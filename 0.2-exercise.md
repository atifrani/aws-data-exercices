# Exercise 02

This exercise aim to automate the loading of the files from AWS s3 to AWS RDS using AWS lambda.

## what is aws lambda:  
AWS Lambda is a compute service that lets you run code without provisioning or managing servers.  
Lambda runs your code on a high-availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, and logging. With Lambda, all you need to do is supply your code in one of the language runtimes that Lambda supports.  

## Lambda Loader
deploy python application with AWS lambda


## Create IAM Role
You start with creation of the IAM role which AWS Lambda function uses for the authorization to call other AWS Services.

1. Login to the AWS Console. Select Ireland as the region.
2. Goto the IAM Management console and click on the Roles menu in the left and then click on the Create role button.
3. On the next screen, select Lambda as the service and click on the Next: Permissions button.
4. On the next screen, select "AWSLambdaBasicExecutionRole", "AmazonRDSFullAccess" and AmazonS3FullAccess as the policy and click on the Next: Tags button.
5. On the next screen, click on the Next: Review button.
6. On the next screen, type in "lambda_s3_rds" for the Role name and click on the Create role button.
7. The role is created in no time. The next step is to create the lambda function.


## Create Lambda loader
You create the Lambda Function to laod csv files from s3 to rds.

1. In the Lambda Console, click on the Functions menu in the left and then click on the Create function button
2. On the next screen, select Author from scratch as the option. Type in "lambda_loader" as the name. 
   Select Python 3.8 as the runtime. Select Use an existing role as the option for the execution role and select aws_lambda_rds for the role.
   Finally, click on the Create function button.
3. The function is created in no time. You will configure Lambda function using code provided with this workshop. Download the project code https://github.com/atifrani/aws-data-exercices from github repository.
4. Import the zip code into your lambda fucntion by clicking on the "Upload from" button and then click on the .zip file option.
5. Add lambda layer,  go to Layers section, click on "add a layer" buttom, select "Specify an ARN". finally add this two layers "arn:aws:lambda:eu-west-1:898466741470:layer:psycopg2-py38:1"  
6. Check lambda configurations.
7. The Lambda function is ready. Let’s now configure the database storage.


## Create Postgresql Table.

You create a postgresql tables.

1. Connect to your postgresql database using BDEAVER.
2. Open a new sql editor and execute the sql queries to create tables.
3. Check if the table exist by runing this quesry "select * from tables"
4. Go to the lambda code and update ther database informations.

## Test in the console.  
Invoke the Lambda function manually using sample Amazon S3 event data.  
To test the Lambda function using the console:    
1. For your function, in the Code tab, under Code source, choose the arrow next to Test, and then choose Configure test event from the dropdown list. 
2. In the Configure test event window, do the following:  
   * Choose Create new test event.  
   * For Event name, enter a name for the test event. For example, "mys3testevent".  
   * For Event sharing settings, choose Private.  
   * For Template, choose S3 Put (s3-put).  
   * In the Event JSON, replace the following values:  
        us-east-1 – The AWS Region where you created the Amazon S3 bucket and the Lambda function "eu-west-1".  
        example-bucket – The Amazon S3 bucket that you created earlier "at-retaildb.  
        test%2Fkey – The name of the sample object that you uploaded to the bucket (for example, departements.csv).  
   * Choose Save.  
3. To invoke the function with your test event, under Code source, choose Test.  
The Execution results tab displays the response, function logs, and request ID.  

## Add trigger.  
Using an Amazon S3 trigger to invoke a Lambda function.  

1. In the Functions page of the Lambda console, choose the function lambda_loader that you created earlier.  
2. Choose Add trigger.  
3. Choose S3 as the source.  
4. For Bucket, choose the bucket you created earlier. Keep the other default settings.  
5. Acknowledge the Recursive invocation warning.  
6. Choose Add.  

## Test the S3 trigger
Invoke your function when you upload a file to the Amazon S3 source bucket. 

To test the Lambda function using the S3 trigger  
   * On the Buckets page of the Amazon S3 console, choose the name of the source bucket that you created earlier.  
   * Remove the existing files  
   * On the Upload page, upload .csv files to the bucket.  
   * Open the Functions page of the Lambda console.  
   * Choose the name of your function (lambda_loader).  
   * To verify that the function ran once for each file that you uploaded, choose the Monitor tab. This page shows graphs for the metrics that Lambda sends to CloudWatch. The count in the Invocations graph should match the number of files that you uploaded to the Amazon S3 bucket.  
   * To view the logs in the CloudWatch console, choose View logs in CloudWatch. Choose a log stream to view the logs output for one of the function invocations.  


##  Clean up your resources
You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent unnecessary charges to your AWS account.  

To delete the Lambda function  
1. Open the Functions page of the Lambda console.  
2. Select the function that you created.  
3. Choose Actions, Delete.  
4. Type delete in the text input field and choose Delete.  

To delete the execution role  
1. Open the Roles page of the IAM console.  
2. Select the execution role that you created.  
3. Choose Delete.  
4. Enter the name of the role in the text input field and choose Delete.  

To delete the S3 bucket  
1. Open the Amazon S3 console.  
2. Select the bucket you created.  
3. Choose Delete.  
4. Enter the name of the bucket in the text input field.  
5. Choose Delete bucket.

